{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69kCBmfOEInQ"
      },
      "source": [
        "#importing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdDVWeW9dPgn",
        "outputId": "93ff9b45-e44f-4c1b-da75-d1a0d7bed8cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2VveNf5cA13Y"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install community\n",
        "!pip install python-louvain\n",
        "!pip install tsia\n",
        "!pip install networkx\n",
        "!pip install easydev\n",
        "!pip install colormap\n",
        "!pip install tomaster\n",
        "!pip install karateclub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sIQBOfFgceFD"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import sys\n",
        "import seaborn as sns\n",
        "\n",
        "from matplotlib import gridspec\n",
        "from numba import njit, prange\n",
        "from pyts.image import MarkovTransitionField\n",
        "\n",
        "import tsia.plot\n",
        "import tsia.markov\n",
        "import tsia.network_graph\n",
        "\n",
        "import community\n",
        "from community import community_louvain\n",
        "import networkx as nx\n",
        "\n",
        "from matplotlib.colors import to_hex\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.mixture import GaussianMixture\n",
        "import numpy as np\n",
        "from scipy.stats import kurtosis, skew\n",
        "\n",
        "import csv\n",
        "from colormap import rgb2hex\n",
        "from tomaster import tomato\n",
        "\n",
        "from karateclub import MUSAE\n",
        "from karateclub import GraphWave\n",
        "from karateclub import Role2Vec\n",
        "from karateclub import Diff2Vec\n",
        "from karateclub import FeatherNode\n",
        "from karateclub import AE\n",
        "from karateclub import NEU\n",
        "from karateclub import GEMSEC\n",
        "from karateclub import EdMot\n",
        "from karateclub import SCD\n",
        "from karateclub import NodeSketch\n",
        "from karateclub import GeoScattering\n",
        "from karateclub import FSCNMF\n",
        "from karateclub import NetMF \n",
        "from karateclub import GLEE\n",
        "from karateclub import DeepWalk\n",
        "\n",
        "import seaborn as sns\n",
        "from pickle import FALSE\n",
        "import scipy\n",
        "import scipy.sparse as sparse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uICSv_sdENWc"
      },
      "source": [
        "#funcs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vKbzzXUHFiPJ"
      },
      "outputs": [],
      "source": [
        "# Useful constants definition\n",
        "COLORMAP = 'jet'\n",
        "\n",
        "def get_network_graph2(mtf):\n",
        "    # Build the graph with networkx:\n",
        "    graph = nx.from_numpy_matrix(mtf)\n",
        "    \n",
        "    # Loops through the edges to get associate each of them with the\n",
        "    # corresponding Markov transition probability:\n",
        "    weights = [mtf[u,v] for u,v in graph.edges()]\n",
        "    for index, e in enumerate(graph.edges()):\n",
        "        graph[e[0]][e[1]]['weight'] = weights[index]\n",
        "        \n",
        "    return graph\n",
        "    \n",
        "def compute_network_graph_statistics2(partitions, graph=None, mtf=None):    \n",
        "    if (graph is None) and (mtf is not None):\n",
        "        graph = get_network_graph(mtf)\n",
        "        \n",
        "    #partitions = community_louvain.best_partition(graph, random_state=1234)\n",
        "    nb_partitions = len(set(partitions.values()))\n",
        "    modularity = community_louvain.modularity(partitions, graph)\n",
        "\n",
        "    \n",
        "    diameter = nx.diameter(graph)\n",
        "    node_size = list(nx.clustering(graph, weight='weight').values())\n",
        "    avg_clustering_coeff = np.array(node_size).mean()\n",
        "    density = nx.density(graph)\n",
        "    avg_path_length = nx.average_shortest_path_length(graph, weight='weight', method='dijkstra')\n",
        "    \n",
        "    average_degree = nx.average_degree_connectivity(graph)\n",
        "    average_degree = np.mean(list(average_degree.values()))\n",
        "    avg_weighted_degree = nx.average_degree_connectivity(graph, weight='weight')\n",
        "    avg_weighted_degree = np.mean(list(avg_weighted_degree.values()))\n",
        "    \n",
        "    statistics = {\n",
        "        'Diameter': diameter,\n",
        "        'Average degree': average_degree,\n",
        "        'Average weighted degree': avg_weighted_degree,\n",
        "        'Density': density,\n",
        "        'Average path length': avg_path_length,\n",
        "        'Average clustering coefficient': avg_clustering_coeff,\n",
        "        'Modularity': modularity,\n",
        "        'Partitions': nb_partitions\n",
        "    }\n",
        "    \n",
        "    return statistics\n",
        "    \n",
        "def get_modularity_encoding2(graph, colormap=COLORMAP, reversed_cmap=False):\n",
        "  \n",
        "    if reversed_cmap == True:\n",
        "        colormap = plt.cm.get_cmap(colormap).reversed()\n",
        "    else:\n",
        "        colormap = plt.cm.get_cmap(colormap)\n",
        "    \n",
        "    # Get the node partitions and number of partitions found with the Louvain\n",
        "    # algorithm, as implemented in the `community` package:\n",
        "\n",
        "    partitions = community_louvain.best_partition(graph, random_state=1234)\n",
        "    #####################################\n",
        "    \n",
        "    nb_partitions = len(set(partitions.values()))\n",
        "    #print(\"nb_partitions: \",nb_partitions)\n",
        "\n",
        "    # Compute node colors and edges colors for the modularity encoding:\n",
        "    edge_colors = [to_hex(colormap(partitions.get(v)/(nb_partitions - 1))) for u,v in graph.edges()]\n",
        "    node_colors = [partitions.get(node) for node in graph.nodes()]\n",
        "    node_size = list(nx.clustering(graph, weight='weight').values())\n",
        "    node_size = list((node_size - np.min(node_size)) * 2000 + 10)\n",
        "    \n",
        "    # Store the encoding to return in a dictionnary:\n",
        "    #print(\"node_colors: \",len(set(node_colors)))\n",
        "\n",
        "    encoding = {\n",
        "        'node_size': node_size,\n",
        "        'edge_color': edge_colors,\n",
        "        'node_color': node_colors\n",
        "    }\n",
        "    return encoding, partitions\n",
        "\n",
        "def foo(w,m,v):\n",
        "  x2=[]\n",
        "  x3=[]\n",
        "  x4=[]\n",
        "  n=len(w)\n",
        "  for j in range(n):\n",
        "    x2.append(v[j]+m[j]**2)\n",
        "    x3.append(pow(m[j],3)+3*m[j]*v[j])\n",
        "    x4.append(pow(m[j],4)+6*m[j]**2*v[j]+3*v[j]**2)\n",
        "  X1=np.dot(w,m)\n",
        "  X2=np.dot(w,x2)\n",
        "  X3=np.dot(w,x3)\n",
        "  X4=np.dot(w,x4)\n",
        "  mu=X1\n",
        "  sig=np.sqrt(np.subtract(X2, mu**2))\n",
        "  sk=(X3-3*X2*X1+2*pow(X1,3))/pow(sig,3)\n",
        "  kur=(X4-4*X3*X1+6*X2*X1**2-3*pow(X1,4))/pow(sig,4)\n",
        "  return [mu, sig, sk, kur]\n",
        "\n",
        "def get_network_graph_map2(timeseries, encoding, colormap=COLORMAP, reversed_cmap=False):\n",
        "   \n",
        "    # Get encoding definitions:\n",
        "    node_colors = encoding['node_color']\n",
        "\n",
        "    #print(node_colors)\n",
        "\n",
        "    image_size = len(node_colors)\n",
        "    #print(\"node_colors\",node_colors)\n",
        "    #print(\"np.max(node_colors)\",np.max(node_colors))\n",
        "    partition_color = node_colors / np.max(node_colors)\n",
        "\n",
        "    # Define the color map:\n",
        "    if reversed_cmap == True:\n",
        "        colormap = plt.cm.get_cmap(colormap).reversed()\n",
        "    else:\n",
        "        colormap = plt.cm.get_cmap(colormap)\n",
        "\n",
        "    # Plot each subset of the signal with the color associated to the network\n",
        "    # graph partition it belongs to:\n",
        "    network_graph_map = []\n",
        "    sequences_width = timeseries.shape[0] / image_size\n",
        "\n",
        "    #df=pd.DataFrame([{\"color\": p ,\"value\": k}])\n",
        "\n",
        "    for i in range(image_size):\n",
        "        c = colormap(partition_color[i])\n",
        "\n",
        "        start = int(i * sequences_width)\n",
        "        end = int((i+1) * sequences_width)#-1\n",
        "        data = timeseries.iloc[start:end, :]\n",
        "\n",
        "        current_map = dict()\n",
        "\n",
        "        current_map.update({\n",
        "            'color': c,\n",
        "            'slice': data\n",
        "        })\n",
        "\n",
        "        #print(len(current_map[\"slice\"]))\n",
        "\n",
        "        network_graph_map.append(current_map)\n",
        "        \n",
        "    return network_graph_map, node_colors\n",
        "\n",
        "\n",
        "def inversemapAna(ng_map2,colors2):\n",
        "\n",
        "  df=pd.DataFrame(columns=[\"color\",\"value\"])\n",
        "  dout=pd.DataFrame(columns=[\"color\",\"value\"])\n",
        "\n",
        "  #if (len(ng_map2)!=len(colors2)):\n",
        "  #    print(\"ERROR\")\n",
        "\n",
        "  for i in range(len(ng_map2)):\n",
        "      d=ng_map2[i]\n",
        "      p=colors2[i]\n",
        "      slic=d[\"slice\"].values.reshape(-1)\n",
        "\n",
        "      for k in slic:\n",
        "        df=df.append([{\"color\": p ,\"value\": k}], ignore_index=True)\n",
        "  \n",
        "  df[\"diff\"]=df[\"value\"]-df[\"value\"].shift(1)\n",
        "  df.drop(df.index[[0]], inplace=True)\n",
        "  df.drop(['value'], axis = 1, inplace=True)\n",
        "  df.rename(columns = {'diff':'value'}, inplace = True)\n",
        "  #print(df)\n",
        "  return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSKTK5AbD7rX"
      },
      "source": [
        "#Generate embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mkS8_W5OG48c"
      },
      "outputs": [],
      "source": [
        "#features=sparse.coo_matrix(np.array(returns[hub].values))\n",
        "#r = pd.read_pickle(\"/content/drive/MyDrive/Mari/Paper3/Hubs_rawdata/rendimenti.pk\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wIjHMbxm7wxb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88ae6735-565c-4112-b9d5-ef96d7bb4e2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "(1826, 128)\n",
            "4\n",
            "(1826, 128)\n",
            "6\n",
            "(1826, 128)\n",
            "8\n",
            "(1826, 128)\n",
            "10\n",
            "(1826, 128)\n",
            "12\n",
            "(1826, 128)\n",
            "14\n",
            "(1826, 128)\n",
            "16\n",
            "(1826, 128)\n",
            "18\n",
            "(1826, 128)\n",
            "20\n",
            "(1826, 128)\n",
            "22\n",
            "(1826, 128)\n",
            "24\n",
            "(1826, 128)\n",
            "26\n",
            "(1826, 128)\n",
            "28\n",
            "(1826, 128)\n",
            "30\n",
            "(1826, 128)\n",
            "32\n",
            "(1826, 128)\n",
            "34\n",
            "(1826, 128)\n",
            "36\n",
            "(1826, 128)\n",
            "38\n",
            "(1826, 128)\n",
            "40\n",
            "(1826, 128)\n",
            "42\n",
            "(1826, 128)\n",
            "44\n",
            "(1826, 128)\n",
            "46\n",
            "(1826, 128)\n",
            "48\n",
            "(1826, 128)\n",
            "50\n",
            "(1826, 128)\n",
            "52\n",
            "(1826, 128)\n",
            "54\n",
            "(1826, 128)\n",
            "56\n",
            "(1826, 128)\n",
            "58\n",
            "(1826, 128)\n",
            "60\n",
            "(1826, 128)\n",
            "62\n",
            "(1826, 128)\n",
            "64\n",
            "(1826, 128)\n",
            "66\n",
            "(1826, 128)\n",
            "68\n",
            "(1826, 128)\n",
            "70\n",
            "(1826, 128)\n",
            "72\n",
            "(1826, 128)\n",
            "74\n",
            "(1826, 128)\n",
            "76\n",
            "(1826, 128)\n",
            "78\n",
            "(1826, 128)\n",
            "80\n",
            "(1826, 128)\n",
            "82\n",
            "(1826, 128)\n",
            "84\n",
            "(1826, 128)\n",
            "86\n",
            "(1826, 128)\n",
            "88\n",
            "(1826, 128)\n",
            "90\n",
            "(1826, 128)\n",
            "92\n",
            "(1826, 128)\n",
            "94\n",
            "(1826, 128)\n",
            "96\n",
            "(1826, 128)\n",
            "98\n",
            "(1826, 128)\n",
            "100\n",
            "(1826, 128)\n",
            "2\n",
            "(1826, 128)\n",
            "4\n",
            "(1826, 128)\n",
            "6\n",
            "(1826, 128)\n",
            "8\n",
            "(1826, 128)\n",
            "10\n",
            "(1826, 128)\n",
            "12\n",
            "(1826, 128)\n",
            "14\n",
            "(1826, 128)\n",
            "16\n",
            "(1826, 128)\n",
            "18\n",
            "(1826, 128)\n",
            "20\n",
            "(1826, 128)\n",
            "22\n",
            "(1826, 128)\n",
            "24\n",
            "(1826, 128)\n",
            "26\n",
            "(1826, 128)\n",
            "28\n",
            "(1826, 128)\n",
            "30\n",
            "(1826, 128)\n",
            "32\n",
            "(1826, 128)\n",
            "34\n",
            "(1826, 128)\n",
            "36\n",
            "(1826, 128)\n",
            "38\n",
            "(1826, 128)\n",
            "40\n",
            "(1826, 128)\n",
            "42\n",
            "(1826, 128)\n",
            "44\n",
            "(1826, 128)\n",
            "46\n",
            "(1826, 128)\n",
            "48\n",
            "(1826, 128)\n",
            "50\n",
            "(1826, 128)\n",
            "52\n",
            "(1826, 128)\n",
            "54\n",
            "(1826, 128)\n",
            "56\n",
            "(1826, 128)\n",
            "58\n",
            "(1826, 128)\n",
            "60\n",
            "(1826, 128)\n",
            "62\n",
            "(1826, 128)\n",
            "64\n",
            "(1826, 128)\n",
            "66\n",
            "(1826, 128)\n",
            "68\n",
            "(1826, 128)\n",
            "70\n",
            "(1826, 128)\n",
            "72\n",
            "(1826, 128)\n",
            "74\n",
            "(1826, 128)\n",
            "76\n",
            "(1826, 128)\n",
            "78\n",
            "(1826, 128)\n",
            "80\n",
            "(1826, 128)\n",
            "82\n",
            "(1826, 128)\n",
            "84\n",
            "(1826, 128)\n",
            "86\n",
            "(1826, 128)\n",
            "88\n",
            "(1826, 128)\n",
            "90\n",
            "(1826, 128)\n",
            "92\n",
            "(1826, 128)\n",
            "94\n",
            "(1826, 128)\n",
            "96\n",
            "(1826, 128)\n",
            "98\n",
            "(1826, 128)\n",
            "100\n",
            "(1826, 128)\n",
            "2\n",
            "(1826, 128)\n",
            "4\n",
            "(1826, 128)\n",
            "6\n",
            "(1826, 128)\n",
            "8\n",
            "(1826, 128)\n",
            "10\n",
            "(1826, 128)\n",
            "12\n",
            "(1826, 128)\n",
            "14\n",
            "(1826, 128)\n",
            "16\n",
            "(1826, 128)\n",
            "18\n",
            "(1826, 128)\n",
            "20\n",
            "(1826, 128)\n",
            "22\n",
            "(1826, 128)\n",
            "24\n",
            "(1826, 128)\n",
            "26\n",
            "(1826, 128)\n",
            "28\n",
            "(1826, 128)\n",
            "30\n",
            "(1826, 128)\n",
            "32\n",
            "(1826, 128)\n",
            "34\n",
            "(1826, 128)\n",
            "36\n",
            "(1826, 128)\n",
            "38\n",
            "(1826, 128)\n",
            "40\n",
            "(1826, 128)\n",
            "42\n",
            "(1826, 128)\n",
            "44\n",
            "(1826, 128)\n",
            "46\n",
            "(1826, 128)\n",
            "48\n",
            "(1826, 128)\n",
            "50\n",
            "(1826, 128)\n",
            "52\n",
            "(1826, 128)\n",
            "54\n",
            "(1826, 128)\n",
            "56\n",
            "(1826, 128)\n",
            "58\n",
            "(1826, 128)\n",
            "60\n",
            "(1826, 128)\n",
            "62\n",
            "(1826, 128)\n",
            "64\n",
            "(1826, 128)\n",
            "66\n",
            "(1826, 128)\n",
            "68\n",
            "(1826, 128)\n",
            "70\n",
            "(1826, 128)\n",
            "72\n",
            "(1826, 128)\n",
            "74\n",
            "(1826, 128)\n",
            "76\n",
            "(1826, 128)\n",
            "78\n",
            "(1826, 128)\n",
            "80\n",
            "(1826, 128)\n",
            "82\n",
            "(1826, 128)\n",
            "84\n",
            "(1826, 128)\n",
            "86\n",
            "(1826, 128)\n",
            "88\n",
            "(1826, 128)\n",
            "90\n",
            "(1826, 128)\n",
            "92\n",
            "(1826, 128)\n",
            "94\n",
            "(1826, 128)\n",
            "96\n",
            "(1826, 128)\n",
            "98\n",
            "(1826, 128)\n",
            "100\n",
            "(1826, 128)\n",
            "2\n",
            "(1826, 128)\n",
            "4\n",
            "(1826, 128)\n",
            "6\n",
            "(1826, 128)\n",
            "8\n",
            "(1826, 128)\n",
            "10\n",
            "(1826, 128)\n",
            "12\n",
            "(1826, 128)\n",
            "14\n",
            "(1826, 128)\n",
            "16\n",
            "(1826, 128)\n",
            "18\n",
            "(1826, 128)\n",
            "20\n",
            "(1826, 128)\n",
            "22\n",
            "(1826, 128)\n",
            "24\n",
            "(1826, 128)\n",
            "26\n",
            "(1826, 128)\n",
            "28\n",
            "(1826, 128)\n",
            "30\n",
            "(1826, 128)\n",
            "32\n",
            "(1826, 128)\n",
            "34\n",
            "(1826, 128)\n",
            "36\n",
            "(1826, 128)\n",
            "38\n",
            "(1826, 128)\n",
            "40\n",
            "(1826, 128)\n",
            "42\n",
            "(1826, 128)\n",
            "44\n",
            "(1826, 128)\n",
            "46\n",
            "(1826, 128)\n",
            "48\n",
            "(1826, 128)\n",
            "50\n",
            "(1826, 128)\n",
            "52\n",
            "(1826, 128)\n",
            "54\n",
            "(1826, 128)\n",
            "56\n",
            "(1826, 128)\n",
            "58\n",
            "(1826, 128)\n",
            "60\n",
            "(1826, 128)\n",
            "62\n",
            "(1826, 128)\n",
            "64\n",
            "(1826, 128)\n",
            "66\n",
            "(1826, 128)\n",
            "68\n",
            "(1826, 128)\n",
            "70\n",
            "(1826, 128)\n",
            "72\n",
            "(1826, 128)\n",
            "74\n",
            "(1826, 128)\n",
            "76\n",
            "(1826, 128)\n",
            "78\n",
            "(1826, 128)\n",
            "80\n",
            "(1826, 128)\n",
            "82\n",
            "(1826, 128)\n",
            "84\n",
            "(1826, 128)\n",
            "86\n",
            "(1826, 128)\n",
            "88\n",
            "(1826, 128)\n",
            "90\n",
            "(1826, 128)\n",
            "92\n",
            "(1826, 128)\n",
            "94\n",
            "(1826, 128)\n",
            "96\n",
            "(1826, 128)\n",
            "98\n",
            "(1826, 128)\n",
            "100\n",
            "(1826, 128)\n"
          ]
        }
      ],
      "source": [
        "hubnames=[\"paloverde\",\"nepool\"]\n",
        "strategies=[\"quantile\",\"normal\"]\n",
        "tag_data = pd.read_pickle(\"/content/drive/MyDrive/Mari/Paper3/Hubs_rawdata/logprezzidepurati.pk\")\n",
        "binslist=range(2,102,2)\n",
        "models=[Diff2Vec()]\n",
        "#returns = pd.read_pickle(\"/content/drive/MyDrive/Mari/Paper3/Hubs_rawdata/rendimenti.pk\")\n",
        "\n",
        "for hub in hubnames:\n",
        "  for model in models:\n",
        "    for strategy in strategies:\n",
        "      for bins in binslist:\n",
        "        print(bins)\n",
        "\n",
        "        tag_data = pd.read_pickle(\"/content/drive/MyDrive/Mari/Paper3/Hubs_rawdata/logprezzidepurati.pk\")\n",
        "        #tag_data=tag_data.iloc[1:]\n",
        "        tag_df=tag_data[hub]\n",
        "                \n",
        "        X = tag_df.values.reshape(1, -1)\n",
        "        \n",
        "        mtf = MarkovTransitionField(image_size=len(tag_df), n_bins=bins, strategy=strategy, overlapping=False)\n",
        "        tag_mtf = mtf.fit_transform(X) \n",
        "\n",
        "        graph= get_network_graph2(tag_mtf[0])\n",
        "        #features=sparse.coo_matrix(np.array(returns[hub].values))\n",
        "\n",
        "        model.fit(graph)#, features)\n",
        "        embedding=model.get_embedding()\n",
        "        print(embedding.shape)\n",
        "        \n",
        "        np.savetxt(\"/content/drive/MyDrive/Mari/Paper3/Embed2/\"+\"Diff2Vec\"+\"/\"+hub+\"/\"+strategy+\"_bins_\"+str(bins)+\".txt\", embedding)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZAIBnrSDcLcR"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "uICSv_sdENWc",
        "LWEhEPJOcu2p"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}